{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Learning_Spark_SQL_Dataframe_Datasets.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SahaRahul/Playing-With-Spark/blob/master/Learning_Spark_SQL_Dataframe_Datasets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzzF6mDd5W6s",
        "colab_type": "text"
      },
      "source": [
        "Install pyspark to work with Spark"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfajmzZk6cnB",
        "colab_type": "code",
        "outputId": "93c97d16-27d6-4d10-ad90-d2bbd56c7f2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "source": [
        "pip install pyspark"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/21/f05c186f4ddb01d15d0ddc36ef4b7e3cedbeb6412274a41f26b55a650ee5/pyspark-2.4.4.tar.gz (215.7MB)\n",
            "\u001b[K     |████████████████████████████████| 215.7MB 53kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/53/c737818eb9a7dc32a7cd4f1396e787bd94200c3997c72c1dbe028587bd76/py4j-0.10.7-py2.py3-none-any.whl (197kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 46.6MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-2.4.4-py2.py3-none-any.whl size=216130387 sha256=7aff0ee5ddfb622538023832759378f06f5e68ab4c1123c428b453231a15feee\n",
            "  Stored in directory: /root/.cache/pip/wheels/ab/09/4d/0d184230058e654eb1b04467dbc1292f00eaa186544604b471\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.7 pyspark-2.4.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0AEqt9S05OYK",
        "colab_type": "text"
      },
      "source": [
        "The entry point into all functionality in Spark is the SparkSession class. To create a basic SparkSession, just use **SparkSession.builder**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVqb4B903ZR_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .appName(\"Python Spark SQL basic example\") \\\n",
        "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
        "    .getOrCreate()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttZqZVBJB4bZ",
        "colab_type": "code",
        "outputId": "fd185431-dcac-48dc-d7bd-a5b3ff84db4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "# spark is an existing SparkSession\n",
        "df = spark.read.json(\"/content/sample_data/anscombe.json\")\n",
        "# Displays the content of the DataFrame to stdout\n",
        "df.show()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+----+-----+---------------+\n",
            "|Series|   X|    Y|_corrupt_record|\n",
            "+------+----+-----+---------------+\n",
            "|  null|null| null|              [|\n",
            "|     I|10.0| 8.04|           null|\n",
            "|     I| 8.0| 6.95|           null|\n",
            "|     I|13.0| 7.58|           null|\n",
            "|     I| 9.0| 8.81|           null|\n",
            "|     I|11.0| 8.33|           null|\n",
            "|     I|14.0| 9.96|           null|\n",
            "|     I| 6.0| 7.24|           null|\n",
            "|     I| 4.0| 4.26|           null|\n",
            "|     I|12.0|10.84|           null|\n",
            "|     I| 7.0| 4.81|           null|\n",
            "|     I| 5.0| 5.68|           null|\n",
            "|    II|10.0| 9.14|           null|\n",
            "|    II| 8.0| 8.14|           null|\n",
            "|    II|13.0| 8.74|           null|\n",
            "|    II| 9.0| 8.77|           null|\n",
            "|    II|11.0| 9.26|           null|\n",
            "|    II|14.0|  8.1|           null|\n",
            "|    II| 6.0| 6.13|           null|\n",
            "|    II| 4.0|  3.1|           null|\n",
            "+------+----+-----+---------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7mPhEeQDajU",
        "colab_type": "code",
        "outputId": "3cc6663c-8d39-41b4-e214-fe91e71813ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# Print the schema in a tree format\n",
        "df.printSchema()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- Series: string (nullable = true)\n",
            " |-- X: double (nullable = true)\n",
            " |-- Y: double (nullable = true)\n",
            " |-- _corrupt_record: string (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCU58sNoNhZ5",
        "colab_type": "code",
        "outputId": "7234d254-c945-4049-b375-c559858c7459",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "# Select only the \"Series\" column\n",
        "df.select(\"Series\").show()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+\n",
            "|Series|\n",
            "+------+\n",
            "|  null|\n",
            "|     I|\n",
            "|     I|\n",
            "|     I|\n",
            "|     I|\n",
            "|     I|\n",
            "|     I|\n",
            "|     I|\n",
            "|     I|\n",
            "|     I|\n",
            "|     I|\n",
            "|     I|\n",
            "|    II|\n",
            "|    II|\n",
            "|    II|\n",
            "|    II|\n",
            "|    II|\n",
            "|    II|\n",
            "|    II|\n",
            "|    II|\n",
            "+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "13bce098-dc29-4ce7-b7aa-0304e77f0945",
        "id": "4XpUrVYiZB3u",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# Select only the \"Series\" column\n",
        "df.select(\"Series\").distinct().show()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+\n",
            "|Series|\n",
            "+------+\n",
            "|  null|\n",
            "|   III|\n",
            "|    IV|\n",
            "|    II|\n",
            "|     I|\n",
            "+------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFgdqZukZA8P",
        "colab_type": "code",
        "outputId": "e74ac4d3-c04a-46e3-e30a-00ae926a8a96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "# Select series not 'null'\n",
        "df.filter(df['Series'] != 'null').show()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+----+-----+---------------+\n",
            "|Series|   X|    Y|_corrupt_record|\n",
            "+------+----+-----+---------------+\n",
            "|     I|10.0| 8.04|           null|\n",
            "|     I| 8.0| 6.95|           null|\n",
            "|     I|13.0| 7.58|           null|\n",
            "|     I| 9.0| 8.81|           null|\n",
            "|     I|11.0| 8.33|           null|\n",
            "|     I|14.0| 9.96|           null|\n",
            "|     I| 6.0| 7.24|           null|\n",
            "|     I| 4.0| 4.26|           null|\n",
            "|     I|12.0|10.84|           null|\n",
            "|     I| 7.0| 4.81|           null|\n",
            "|     I| 5.0| 5.68|           null|\n",
            "|    II|10.0| 9.14|           null|\n",
            "|    II| 8.0| 8.14|           null|\n",
            "|    II|13.0| 8.74|           null|\n",
            "|    II| 9.0| 8.77|           null|\n",
            "|    II|11.0| 9.26|           null|\n",
            "|    II|14.0|  8.1|           null|\n",
            "|    II| 6.0| 6.13|           null|\n",
            "|    II| 4.0|  3.1|           null|\n",
            "|    II|12.0| 9.13|           null|\n",
            "+------+----+-----+---------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXN5bDI1ZT44",
        "colab_type": "code",
        "outputId": "bae28f0d-434e-4566-f141-758af4624d81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# Count people by age\n",
        "df.groupBy(\"Series\").count().show()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+-----+\n",
            "|Series|count|\n",
            "+------+-----+\n",
            "|  null|    2|\n",
            "|   III|   11|\n",
            "|    IV|   11|\n",
            "|    II|   11|\n",
            "|     I|   11|\n",
            "+------+-----+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YsiD-z9GbX-p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Register the DataFrame as a SQL temporary view\n",
        "df.filter(df['Series'] != 'null').createOrReplaceTempView(\"df1\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4_u2q6fbj9o",
        "colab_type": "code",
        "outputId": "01ae580a-575b-4d11-c201-d3e9be6c5625",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "\n",
        "sqlDF = spark.sql(\"SELECT * FROM df1\")\n",
        "sqlDF.show()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+----+-----+---------------+\n",
            "|Series|   X|    Y|_corrupt_record|\n",
            "+------+----+-----+---------------+\n",
            "|     I|10.0| 8.04|           null|\n",
            "|     I| 8.0| 6.95|           null|\n",
            "|     I|13.0| 7.58|           null|\n",
            "|     I| 9.0| 8.81|           null|\n",
            "|     I|11.0| 8.33|           null|\n",
            "|     I|14.0| 9.96|           null|\n",
            "|     I| 6.0| 7.24|           null|\n",
            "|     I| 4.0| 4.26|           null|\n",
            "|     I|12.0|10.84|           null|\n",
            "|     I| 7.0| 4.81|           null|\n",
            "|     I| 5.0| 5.68|           null|\n",
            "|    II|10.0| 9.14|           null|\n",
            "|    II| 8.0| 8.14|           null|\n",
            "|    II|13.0| 8.74|           null|\n",
            "|    II| 9.0| 8.77|           null|\n",
            "|    II|11.0| 9.26|           null|\n",
            "|    II|14.0|  8.1|           null|\n",
            "|    II| 6.0| 6.13|           null|\n",
            "|    II| 4.0|  3.1|           null|\n",
            "|    II|12.0| 9.13|           null|\n",
            "+------+----+-----+---------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZDgAiVdcFJ0",
        "colab_type": "code",
        "outputId": "14f3d7b7-16fa-46c6-9a77-e67d8204c8e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "sqlDF.show()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+----+-----+---------------+\n",
            "|Series|   X|    Y|_corrupt_record|\n",
            "+------+----+-----+---------------+\n",
            "|     I|10.0| 8.04|           null|\n",
            "|     I| 8.0| 6.95|           null|\n",
            "|     I|13.0| 7.58|           null|\n",
            "|     I| 9.0| 8.81|           null|\n",
            "|     I|11.0| 8.33|           null|\n",
            "|     I|14.0| 9.96|           null|\n",
            "|     I| 6.0| 7.24|           null|\n",
            "|     I| 4.0| 4.26|           null|\n",
            "|     I|12.0|10.84|           null|\n",
            "|     I| 7.0| 4.81|           null|\n",
            "|     I| 5.0| 5.68|           null|\n",
            "|    II|10.0| 9.14|           null|\n",
            "|    II| 8.0| 8.14|           null|\n",
            "|    II|13.0| 8.74|           null|\n",
            "|    II| 9.0| 8.77|           null|\n",
            "|    II|11.0| 9.26|           null|\n",
            "|    II|14.0|  8.1|           null|\n",
            "|    II| 6.0| 6.13|           null|\n",
            "|    II| 4.0|  3.1|           null|\n",
            "|    II|12.0| 9.13|           null|\n",
            "+------+----+-----+---------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7CWHzg1d0mR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Register the DataFrame as a global temporary view\n",
        "df.filter(df['Series'] != 'null').createGlobalTempView(\"df2\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahbj8QzhU5UN",
        "colab_type": "code",
        "outputId": "5b04440e-6f54-480e-f091-704d81102f02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "spark.sql(\"SELECT * FROM global_temp.df2\").show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+----+-----+---------------+\n",
            "|Series|   X|    Y|_corrupt_record|\n",
            "+------+----+-----+---------------+\n",
            "|     I|10.0| 8.04|           null|\n",
            "|     I| 8.0| 6.95|           null|\n",
            "|     I|13.0| 7.58|           null|\n",
            "|     I| 9.0| 8.81|           null|\n",
            "|     I|11.0| 8.33|           null|\n",
            "|     I|14.0| 9.96|           null|\n",
            "|     I| 6.0| 7.24|           null|\n",
            "|     I| 4.0| 4.26|           null|\n",
            "|     I|12.0|10.84|           null|\n",
            "|     I| 7.0| 4.81|           null|\n",
            "|     I| 5.0| 5.68|           null|\n",
            "|    II|10.0| 9.14|           null|\n",
            "|    II| 8.0| 8.14|           null|\n",
            "|    II|13.0| 8.74|           null|\n",
            "|    II| 9.0| 8.77|           null|\n",
            "|    II|11.0| 9.26|           null|\n",
            "|    II|14.0|  8.1|           null|\n",
            "|    II| 6.0| 6.13|           null|\n",
            "|    II| 4.0|  3.1|           null|\n",
            "|    II|12.0| 9.13|           null|\n",
            "+------+----+-----+---------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tI7DiQJteKmv",
        "colab_type": "code",
        "outputId": "c8b2dc8c-01b8-4e72-8ee3-c76f372a3b22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "# Global temporary view is tied to a system preserved database `global_temp`\n",
        "spark.sql(\"SELECT * FROM global_temp.df2\").show()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+----+-----+---------------+\n",
            "|Series|   X|    Y|_corrupt_record|\n",
            "+------+----+-----+---------------+\n",
            "|     I|10.0| 8.04|           null|\n",
            "|     I| 8.0| 6.95|           null|\n",
            "|     I|13.0| 7.58|           null|\n",
            "|     I| 9.0| 8.81|           null|\n",
            "|     I|11.0| 8.33|           null|\n",
            "|     I|14.0| 9.96|           null|\n",
            "|     I| 6.0| 7.24|           null|\n",
            "|     I| 4.0| 4.26|           null|\n",
            "|     I|12.0|10.84|           null|\n",
            "|     I| 7.0| 4.81|           null|\n",
            "|     I| 5.0| 5.68|           null|\n",
            "|    II|10.0| 9.14|           null|\n",
            "|    II| 8.0| 8.14|           null|\n",
            "|    II|13.0| 8.74|           null|\n",
            "|    II| 9.0| 8.77|           null|\n",
            "|    II|11.0| 9.26|           null|\n",
            "|    II|14.0|  8.1|           null|\n",
            "|    II| 6.0| 6.13|           null|\n",
            "|    II| 4.0|  3.1|           null|\n",
            "|    II|12.0| 9.13|           null|\n",
            "+------+----+-----+---------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRGSAy8jeZ6u",
        "colab_type": "code",
        "outputId": "6270b72f-3d5f-453b-f969-9abd4ff62a6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "# Global temporary view is cross-session\n",
        "spark.newSession().sql(\"SELECT * FROM global_temp.df2\").show()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+----+-----+---------------+\n",
            "|Series|   X|    Y|_corrupt_record|\n",
            "+------+----+-----+---------------+\n",
            "|     I|10.0| 8.04|           null|\n",
            "|     I| 8.0| 6.95|           null|\n",
            "|     I|13.0| 7.58|           null|\n",
            "|     I| 9.0| 8.81|           null|\n",
            "|     I|11.0| 8.33|           null|\n",
            "|     I|14.0| 9.96|           null|\n",
            "|     I| 6.0| 7.24|           null|\n",
            "|     I| 4.0| 4.26|           null|\n",
            "|     I|12.0|10.84|           null|\n",
            "|     I| 7.0| 4.81|           null|\n",
            "|     I| 5.0| 5.68|           null|\n",
            "|    II|10.0| 9.14|           null|\n",
            "|    II| 8.0| 8.14|           null|\n",
            "|    II|13.0| 8.74|           null|\n",
            "|    II| 9.0| 8.77|           null|\n",
            "|    II|11.0| 9.26|           null|\n",
            "|    II|14.0|  8.1|           null|\n",
            "|    II| 6.0| 6.13|           null|\n",
            "|    II| 4.0|  3.1|           null|\n",
            "|    II|12.0| 9.13|           null|\n",
            "+------+----+-----+---------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTtRswySe4qA",
        "colab_type": "code",
        "outputId": "60c53824-63f5-4930-fcc8-6d0ebfd909e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "spark.sql(\"SELECT Series, X, Y FROM global_temp.df2\").show()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+----+-----+\n",
            "|Series|   X|    Y|\n",
            "+------+----+-----+\n",
            "|     I|10.0| 8.04|\n",
            "|     I| 8.0| 6.95|\n",
            "|     I|13.0| 7.58|\n",
            "|     I| 9.0| 8.81|\n",
            "|     I|11.0| 8.33|\n",
            "|     I|14.0| 9.96|\n",
            "|     I| 6.0| 7.24|\n",
            "|     I| 4.0| 4.26|\n",
            "|     I|12.0|10.84|\n",
            "|     I| 7.0| 4.81|\n",
            "|     I| 5.0| 5.68|\n",
            "|    II|10.0| 9.14|\n",
            "|    II| 8.0| 8.14|\n",
            "|    II|13.0| 8.74|\n",
            "|    II| 9.0| 8.77|\n",
            "|    II|11.0| 9.26|\n",
            "|    II|14.0|  8.1|\n",
            "|    II| 6.0| 6.13|\n",
            "|    II| 4.0|  3.1|\n",
            "|    II|12.0| 9.13|\n",
            "+------+----+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GF8jeLEyspP8",
        "colab_type": "text"
      },
      "source": [
        "To load a JSON file you can use:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQ6IEdywq3fp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_series = spark.read.load(\"/content/sample_data/anscombe.json\", format=\"json\")\n",
        "df_series.select(\"Series\", \"X\").write.save(\"XSeries.parquet\", format=\"parquet\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16trWHKesvlk",
        "colab_type": "text"
      },
      "source": [
        "To load a CSV file you can use:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZMSfAicrr65",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_cali = spark.read.load(\"/content/sample_data/california_housing_test.csv\",\n",
        "                     format=\"csv\", sep=\",\", inferSchema=\"true\", header=\"true\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNQU0FXcuxgv",
        "colab_type": "code",
        "outputId": "567faeb4-60c5-4510-bd04-9f3aa619830d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "df_cali.show()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+\n",
            "|longitude|latitude|housing_median_age|total_rooms|total_bedrooms|population|households|median_income|median_house_value|\n",
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+\n",
            "|  -122.05|   37.37|              27.0|     3885.0|         661.0|    1537.0|     606.0|       6.6085|          344700.0|\n",
            "|   -118.3|   34.26|              43.0|     1510.0|         310.0|     809.0|     277.0|        3.599|          176500.0|\n",
            "|  -117.81|   33.78|              27.0|     3589.0|         507.0|    1484.0|     495.0|       5.7934|          270500.0|\n",
            "|  -118.36|   33.82|              28.0|       67.0|          15.0|      49.0|      11.0|       6.1359|          330000.0|\n",
            "|  -119.67|   36.33|              19.0|     1241.0|         244.0|     850.0|     237.0|       2.9375|           81700.0|\n",
            "|  -119.56|   36.51|              37.0|     1018.0|         213.0|     663.0|     204.0|       1.6635|           67000.0|\n",
            "|  -121.43|   38.63|              43.0|     1009.0|         225.0|     604.0|     218.0|       1.6641|           67000.0|\n",
            "|  -120.65|   35.48|              19.0|     2310.0|         471.0|    1341.0|     441.0|        3.225|          166900.0|\n",
            "|  -122.84|    38.4|              15.0|     3080.0|         617.0|    1446.0|     599.0|       3.6696|          194400.0|\n",
            "|  -118.02|   34.08|              31.0|     2402.0|         632.0|    2830.0|     603.0|       2.3333|          164200.0|\n",
            "|  -118.24|   33.98|              45.0|      972.0|         249.0|    1288.0|     261.0|       2.2054|          125000.0|\n",
            "|  -119.12|   35.85|              37.0|      736.0|         166.0|     564.0|     138.0|       2.4167|           58300.0|\n",
            "|  -121.93|   37.25|              36.0|     1089.0|         182.0|     535.0|     170.0|         4.69|          252600.0|\n",
            "|  -117.03|   32.97|              16.0|     3936.0|         694.0|    1935.0|     659.0|       4.5625|          231200.0|\n",
            "|  -117.97|   33.73|              27.0|     2097.0|         325.0|    1217.0|     331.0|       5.7121|          222500.0|\n",
            "|  -117.99|   33.81|              42.0|      161.0|          40.0|     157.0|      50.0|          2.2|          153100.0|\n",
            "|  -120.81|   37.53|              15.0|      570.0|         123.0|     189.0|     107.0|        1.875|          181300.0|\n",
            "|   -121.2|   38.69|              26.0|     3077.0|         607.0|    1603.0|     595.0|       2.7174|          137500.0|\n",
            "|  -118.88|   34.21|              26.0|     1590.0|         196.0|     654.0|     199.0|       6.5851|          300000.0|\n",
            "|  -122.59|   38.01|              35.0|     8814.0|        1307.0|    3450.0|    1258.0|       6.1724|          414300.0|\n",
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VvyG1kb4yO7M",
        "colab_type": "code",
        "outputId": "d3fefae9-ebed-4918-89c1-8479d9dc6398",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "df_series.show()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+----+-----+---------------+\n",
            "|Series|   X|    Y|_corrupt_record|\n",
            "+------+----+-----+---------------+\n",
            "|  null|null| null|              [|\n",
            "|     I|10.0| 8.04|           null|\n",
            "|     I| 8.0| 6.95|           null|\n",
            "|     I|13.0| 7.58|           null|\n",
            "|     I| 9.0| 8.81|           null|\n",
            "|     I|11.0| 8.33|           null|\n",
            "|     I|14.0| 9.96|           null|\n",
            "|     I| 6.0| 7.24|           null|\n",
            "|     I| 4.0| 4.26|           null|\n",
            "|     I|12.0|10.84|           null|\n",
            "|     I| 7.0| 4.81|           null|\n",
            "|     I| 5.0| 5.68|           null|\n",
            "|    II|10.0| 9.14|           null|\n",
            "|    II| 8.0| 8.14|           null|\n",
            "|    II|13.0| 8.74|           null|\n",
            "|    II| 9.0| 8.77|           null|\n",
            "|    II|11.0| 9.26|           null|\n",
            "|    II|14.0|  8.1|           null|\n",
            "|    II| 6.0| 6.13|           null|\n",
            "|    II| 4.0|  3.1|           null|\n",
            "+------+----+-----+---------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2tzm6lru-Y8",
        "colab_type": "text"
      },
      "source": [
        "PySpark Usage Guide for Pandas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRVEA1useBSk",
        "colab_type": "code",
        "outputId": "a7de26ce-6064-4584-fc1e-8a48d2fea1ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "!pip install pyspark[sql]"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyspark[sql] in /usr/local/lib/python3.6/dist-packages (2.4.4)\n",
            "Requirement already satisfied: py4j==0.10.7 in /usr/local/lib/python3.6/dist-packages (from pyspark[sql]) (0.10.7)\n",
            "Requirement already satisfied: pyarrow>=0.8.0; extra == \"sql\" in /usr/local/lib/python3.6/dist-packages (from pyspark[sql]) (0.14.1)\n",
            "Requirement already satisfied: pandas>=0.19.2; extra == \"sql\" in /usr/local/lib/python3.6/dist-packages (from pyspark[sql]) (0.25.3)\n",
            "Requirement already satisfied: six>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from pyarrow>=0.8.0; extra == \"sql\"->pyspark[sql]) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.14 in /usr/local/lib/python3.6/dist-packages (from pyarrow>=0.8.0; extra == \"sql\"->pyspark[sql]) (1.17.4)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19.2; extra == \"sql\"->pyspark[sql]) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19.2; extra == \"sql\"->pyspark[sql]) (2.6.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qVyaT94eHeh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Enable Arrow-based columnar data transfers\n",
        "spark.conf.set(\"spark.sql.execution.arrow.enabled\", \"true\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVvl5He-gz-d",
        "colab_type": "text"
      },
      "source": [
        "Arrow is available as an optimization when converting a Spark DataFrame to a Pandas DataFrame using the call toPandas() and when creating a Spark DataFrame from a Pandas DataFrame with createDataFrame(pandas_df). To use Arrow when executing these calls, users need to first set the Spark configuration spark.sql.execution.arrow.enabled to true. This is disabled by default."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYjwR3hLelih",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generate a Pandas DataFrame\n",
        "pdf = pd.DataFrame(np.random.rand(100, 3))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Kk8pszleoot",
        "colab_type": "code",
        "outputId": "91182380-6bc1-41ff-8ac2-c4d4d9235ad7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "pdf"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.819902</td>\n",
              "      <td>0.685389</td>\n",
              "      <td>0.773440</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.789202</td>\n",
              "      <td>0.274083</td>\n",
              "      <td>0.728807</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.976244</td>\n",
              "      <td>0.088917</td>\n",
              "      <td>0.545040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.018148</td>\n",
              "      <td>0.961399</td>\n",
              "      <td>0.871443</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.060115</td>\n",
              "      <td>0.561545</td>\n",
              "      <td>0.398172</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>0.799904</td>\n",
              "      <td>0.328845</td>\n",
              "      <td>0.986573</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>0.291208</td>\n",
              "      <td>0.674858</td>\n",
              "      <td>0.959038</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>0.267140</td>\n",
              "      <td>0.194000</td>\n",
              "      <td>0.298018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>0.001453</td>\n",
              "      <td>0.647985</td>\n",
              "      <td>0.001904</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>0.520601</td>\n",
              "      <td>0.034947</td>\n",
              "      <td>0.169544</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           0         1         2\n",
              "0   0.819902  0.685389  0.773440\n",
              "1   0.789202  0.274083  0.728807\n",
              "2   0.976244  0.088917  0.545040\n",
              "3   0.018148  0.961399  0.871443\n",
              "4   0.060115  0.561545  0.398172\n",
              "..       ...       ...       ...\n",
              "95  0.799904  0.328845  0.986573\n",
              "96  0.291208  0.674858  0.959038\n",
              "97  0.267140  0.194000  0.298018\n",
              "98  0.001453  0.647985  0.001904\n",
              "99  0.520601  0.034947  0.169544\n",
              "\n",
              "[100 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8hA9BB1est4",
        "colab_type": "code",
        "outputId": "19634bff-ff75-41eb-e1d6-559b93d91922",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Create a Spark DataFrame from a Pandas DataFrame using Arrow\n",
        "df = spark.createDataFrame(pdf)\n",
        "df"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[0: double, 1: double, 2: double]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGh2TIN1eyeR",
        "colab_type": "code",
        "outputId": "bea0a86d-d13b-4e98-b5d7-052eae4e248e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Convert the Spark DataFrame back to a Pandas DataFrame using Arrow\n",
        "result_pdf = df.select(\"*\").toPandas()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pyarrow/__init__.py:157: UserWarning: pyarrow.open_stream is deprecated, please use pyarrow.ipc.open_stream\n",
            "  warnings.warn(\"pyarrow.open_stream is deprecated, please use \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9OHnmgye3aY",
        "colab_type": "code",
        "outputId": "62e43f3a-c9a8-482f-9ce4-461bd4d9a15b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "result_pdf"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.819902</td>\n",
              "      <td>0.685389</td>\n",
              "      <td>0.773440</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.789202</td>\n",
              "      <td>0.274083</td>\n",
              "      <td>0.728807</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.976244</td>\n",
              "      <td>0.088917</td>\n",
              "      <td>0.545040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.018148</td>\n",
              "      <td>0.961399</td>\n",
              "      <td>0.871443</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.060115</td>\n",
              "      <td>0.561545</td>\n",
              "      <td>0.398172</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>0.799904</td>\n",
              "      <td>0.328845</td>\n",
              "      <td>0.986573</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>0.291208</td>\n",
              "      <td>0.674858</td>\n",
              "      <td>0.959038</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>0.267140</td>\n",
              "      <td>0.194000</td>\n",
              "      <td>0.298018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>0.001453</td>\n",
              "      <td>0.647985</td>\n",
              "      <td>0.001904</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>0.520601</td>\n",
              "      <td>0.034947</td>\n",
              "      <td>0.169544</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           0         1         2\n",
              "0   0.819902  0.685389  0.773440\n",
              "1   0.789202  0.274083  0.728807\n",
              "2   0.976244  0.088917  0.545040\n",
              "3   0.018148  0.961399  0.871443\n",
              "4   0.060115  0.561545  0.398172\n",
              "..       ...       ...       ...\n",
              "95  0.799904  0.328845  0.986573\n",
              "96  0.291208  0.674858  0.959038\n",
              "97  0.267140  0.194000  0.298018\n",
              "98  0.001453  0.647985  0.001904\n",
              "99  0.520601  0.034947  0.169544\n",
              "\n",
              "[100 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDTAzvlXhA7L",
        "colab_type": "text"
      },
      "source": [
        "**Pandas UDFs (a.k.a. Vectorized UDFs)**\n",
        "\n",
        "Pandas UDFs are user defined functions that are executed by Spark using Arrow to transfer data and Pandas to work with the data. A Pandas UDF is defined using the keyword pandas_udf as a decorator or to wrap the function, no additional configuration is required. Currently, there are two types of Pandas UDF: Scalar and Grouped Map."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8PUuF8aikyh",
        "colab_type": "text"
      },
      "source": [
        "*Scalar*\n",
        "\n",
        "Scalar Pandas UDFs are used for vectorizing scalar operations. They can be used with functions such as select and withColumn. The Python function should take pandas.Series as inputs and return a pandas.Series of the same length. Internally, Spark will execute a Pandas UDF by splitting columns into batches and calling the function for each batch as a subset of the data, then concatenating the results together."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulK1i_nHe8tY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "from pyspark.sql.functions import col, pandas_udf, PandasUDFType\n",
        "from pyspark.sql.types import LongType"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNJL3TRuhNu7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Declare the function and create the UDF\n",
        "def multiply_func(a, b):\n",
        "    return a * b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSXnBX6oj67j",
        "colab_type": "code",
        "outputId": "705fc2f9-3bee-472b-e532-0ccbcc646aa8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "multiply = pandas_udf(multiply_func, returnType=LongType())\n",
        "\n",
        "# The function for a pandas_udf should be able to execute with local Pandas data\n",
        "x = pd.Series([1, 2, 3])\n",
        "print(multiply_func(x, x))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    1\n",
            "1    4\n",
            "2    9\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SLfax6DlY3a",
        "colab_type": "code",
        "outputId": "f5e44732-8763-4310-9a85-7d1c801df794",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!update-java-alternatives --list"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "java-1.11.0-openjdk-amd64      1111       /usr/lib/jvm/java-1.11.0-openjdk-amd64\n",
            "java-1.8.0-openjdk-amd64       1081       /usr/lib/jvm/java-1.8.0-openjdk-amd64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVYQdv7xldee",
        "colab_type": "code",
        "outputId": "425f801d-ec8d-4834-d874-91f762b42b01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "!update-alternatives --config java"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 2 choices for the alternative java (providing /usr/bin/java).\n",
            "\n",
            "  Selection    Path                                            Priority   Status\n",
            "------------------------------------------------------------\n",
            "* 0            /usr/lib/jvm/java-11-openjdk-amd64/bin/java      1111      auto mode\n",
            "  1            /usr/lib/jvm/java-11-openjdk-amd64/bin/java      1111      manual mode\n",
            "  2            /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java   1081      manual mode\n",
            "\n",
            "Press <enter> to keep the current choice[*], or type selection number: 2\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java to provide /usr/bin/java (java) in manual mode\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ru7CWurFkVqf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a Spark DataFrame, 'spark' is an existing SparkSession\n",
        "df = spark.createDataFrame(pd.DataFrame(x, columns=[\"x\"]))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lT0MrOvyulyX",
        "colab_type": "code",
        "outputId": "a50cebc0-6169-49e6-aecb-f464062cf1d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "# Execute function as a Spark vectorized UDF\n",
        "df.show()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+\n",
            "|  x|\n",
            "+---+\n",
            "|  1|\n",
            "|  2|\n",
            "|  3|\n",
            "+---+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxQRFL5o1aLQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.sql.functions import pandas_udf, PandasUDFType\n",
        "\n",
        "# Use pandas_udf to define a Pandas UDF\n",
        "@pandas_udf('double', PandasUDFType.SCALAR)\n",
        "# Input/output are both a pandas.Series of doubles\n",
        "\n",
        "def pandas_plus_one(v):\n",
        "    return v + 1\n",
        "\n",
        "df_x = df.withColumn('v2', pandas_plus_one(df['x']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uoaP-5pk3cIL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.sql.functions import udf\n",
        "\n",
        "# Use udf to define a row-at-a-time udf\n",
        "@udf('double')\n",
        "# Input/output are both a single double value\n",
        "def plus_one(v):\n",
        "      return v + 1\n",
        "\n",
        "df_udf = df.withColumn('v2', plus_one(df.x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPaBcp2UCnDV",
        "colab_type": "code",
        "outputId": "88defed5-3314-42c7-b718-7d979bed821c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df_udf"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[x: bigint, v2: double]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    }
  ]
}